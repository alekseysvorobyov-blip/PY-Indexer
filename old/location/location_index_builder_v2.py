#!/usr/bin/env python3
"""
TECH-LOCATION Builder v2.0 (Compact)

–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–æ–º–ø–∞–∫—Ç–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∞—Å—Å–∏–≤—ã –≤–º–µ—Å—Ç–æ –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python location_index_builder_v2.py <project_path> <tech_index_dir> <output_dir> [options]

–û–ø—Ü–∏–∏:
    --format=json        –§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞: json, json.gz (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é json)
    --minify             –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π JSON (–±–µ–∑ –æ—Ç—Å—Ç—É–ø–æ–≤ –∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫)

–ü—Ä–∏–º–µ—Ä—ã:
    python location_index_builder_v2.py "D:\\PROJECT" "D:\\INDEXES" "D:\\INDEXES"
    python location_index_builder_v2.py "." "./idx" "./idx" --format=json.gz
    python location_index_builder_v2.py "." "./idx" "./idx" --minify
"""

import ast
import json
import hashlib
import os
import sys
import gzip
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
import argparse


class LocationIndexBuilderV2:
    """–ü–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å –∫–æ–º–ø–∞–∫—Ç–Ω–æ–≥–æ TECH-LOCATION –∏–Ω–¥–µ–∫—Å–∞ v2.0"""

    def __init__(self, project_root: str, tech_index_path: str, output_format: str = "json", minify: bool = False):
        self.project_root = Path(project_root).resolve()
        self.tech_index_path = Path(tech_index_path).resolve()
        self.output_format = output_format.lower()
        self.minify = minify

        # –ó–∞–≥—Ä—É–∑–∏—Ç—å TECH-INDEX
        self.tech_index = self._load_tech_index()

        # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã (–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å—Ç—Ä–æ–∫)
        self.paths: List[str] = []
        self.paths_index: Dict[str, int] = {}

        self.modifieds: List[str] = []
        self.modifieds_index: Dict[str, int] = {}

        self.hashes: List[str] = []
        self.hashes_index: Dict[str, int] = {}

        self.decorators: List[str] = []
        self.decorators_index: Dict[str, int] = {}

        self.commenttexts: List[str] = []
        self.commenttexts_index: Dict[str, int] = {}

        # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã (–¥–∞–Ω–Ω—ã–µ)
        self.files: List[List[int]] = []
        self.modules: List[List[int]] = []
        self.classes: List[List] = []
        self.functions: List[List] = []
        self.imports: List[List[int]] = []
        self.comments: List[List[int]] = []

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        self.meta = {
            "version": "2.0",
            "schemaversion": "2.0",
            "indexeddate": datetime.now().isoformat(),
            "techindexhash": self._calculate_tech_index_hash(),
            "projectroot": str(self.project_root),
            "techindexpath": str(self.tech_index_path),
            "totalobjects": {
                "modules": 0,
                "classes": 0,
                "functions": 0,
                "imports": 0,
                "comments": 0
            }
        }

        # –¢–∏–ø—ã –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
        self.comment_types = {
            "TODO": 0, "FIXME": 1, "NOTE": 2, "WARNING": 3,
            "HACK": 4, "XXX": 5, "OPTIMIZE": 6
        }

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ (—Å IGNORECASE –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –ª—é–±–æ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ)
        self.comment_patterns = {
            "TODO": re.compile(r'#\s*TODO[:\s](.*)', re.IGNORECASE),
            "FIXME": re.compile(r'#\s*FIXME[:\s](.*)', re.IGNORECASE),
            "NOTE": re.compile(r'#\s*NOTE[:\s](.*)', re.IGNORECASE),
            "WARNING": re.compile(r'#\s*WARNING[:\s](.*)', re.IGNORECASE),
            "HACK": re.compile(r'#\s*HACK[:\s](.*)', re.IGNORECASE),
            "XXX": re.compile(r'#\s*XXX[:\s](.*)', re.IGNORECASE),
            "OPTIMIZE": re.compile(r'#\s*OPTIMIZE[:\s](.*)', re.IGNORECASE)
        }

    def _add_to_array(self, value: str, array: List[str], index: Dict[str, int]) -> int:
        """–î–æ–±–∞–≤–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –º–∞—Å—Å–∏–≤ —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π"""
        if value in index:
            return index[value]
        idx = len(array)
        array.append(value)
        index[value] = idx
        return idx

    def _load_tech_index(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å TECH-INDEX"""
        if not self.tech_index_path.exists():
            raise FileNotFoundError(f"TECH-INDEX –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.tech_index_path}")

        print(f"üìñ –ó–∞–≥—Ä—É–∑–∫–∞ TECH-INDEX: {self.tech_index_path.name}")

        if self.tech_index_path.suffix == '.gz':
            with gzip.open(self.tech_index_path, 'rt', encoding='utf-8') as f:
                return json.load(f)
        else:
            with open(self.tech_index_path, 'r', encoding='utf-8') as f:
                return json.load(f)

    def _calculate_tech_index_hash(self) -> str:
        """–í—ã—á–∏—Å–ª–∏—Ç—å SHA256 —Ö–µ—à TECH-INDEX"""
        sha256 = hashlib.sha256()

        if self.tech_index_path.suffix == '.gz':
            with gzip.open(self.tech_index_path, 'rb') as f:
                for chunk in iter(lambda: f.read(4096), b''):
                    sha256.update(chunk)
        else:
            with open(self.tech_index_path, 'rb') as f:
                for chunk in iter(lambda: f.read(4096), b''):
                    sha256.update(chunk)

        return sha256.hexdigest()[:16]

    def _calculate_file_hash(self, filepath: Path) -> str:
        """–í—ã—á–∏—Å–ª–∏—Ç—å SHA256 —Ö–µ—à —Ñ–∞–π–ª–∞"""
        sha256 = hashlib.sha256()
        with open(filepath, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b''):
                sha256.update(chunk)
        return sha256.hexdigest()[:16]

    def _process_file_info(self, file_id: int) -> int:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ, –≤–µ—Ä–Ω—É—Ç—å –∏–Ω–¥–µ–∫—Å"""
        file_path_rel = self.tech_index["files"][file_id]
        file_path = self.project_root / file_path_rel

        if not file_path.exists():
            print(f"‚ö† –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path_rel}")
            return -1

        stat = file_path.stat()

        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        # –î–æ–±–∞–≤–∏—Ç—å –≤ –∏–Ω–¥–µ–∫—Å—ã
        path_idx = self._add_to_array(file_path_rel, self.paths, self.paths_index)

        modified_str = datetime.fromtimestamp(stat.st_mtime).isoformat()
        modified_idx = self._add_to_array(modified_str, self.modifieds, self.modifieds_index)

        file_hash = self._calculate_file_hash(file_path)
        hash_idx = self._add_to_array(file_hash, self.hashes, self.hashes_index)

        # [path_idx, line_count, size_bytes, modified_idx, hash_idx]
        self.files.append([path_idx, len(lines), stat.st_size, modified_idx, hash_idx])

        return len(self.files) - 1

    def _parse_file(self, filepath: Path) -> Tuple[Optional[ast.Module], List[str]]:
        """–ü–∞—Ä—Å–∏—Ç—å —Ñ–∞–π–ª"""
        encodings = ['utf-8', 'cp1251', 'latin-1']

        for encoding in encodings:
            try:
                with open(filepath, 'r', encoding=encoding) as f:
                    source = f.read()
                    lines = source.splitlines()

                try:
                    tree = ast.parse(source, filename=str(filepath))
                    return tree, lines
                except SyntaxError:
                    return None, []

            except UnicodeDecodeError:
                if encoding == encodings[-1]:
                    return None, []
                continue
            except Exception:
                return None, []

        return None, []

    def _extract_docstring_coords(self, node) -> Optional[List[int]]:
        """–ò–∑–≤–ª–µ—á—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã docstring [line_start, line_end]"""
        if not node.body:
            return None

        first = node.body[0]
        if isinstance(first, ast.Expr) and isinstance(first.value, ast.Constant):
            if isinstance(first.value.value, str):
                return [first.lineno, first.end_lineno]

        return None

    def _extract_decorators_compact(self, node) -> List[List[int]]:
        """–ò–∑–≤–ª–µ—á—å –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã [[line, decorator_idx], ...]"""
        decorators = []

        for dec in node.decorator_list:
            dec_str = ""

            if isinstance(dec, ast.Name):
                dec_str = f"@{dec.id}"
            elif isinstance(dec, ast.Call):
                if isinstance(dec.func, ast.Name):
                    dec_str = f"@{dec.func.id}(...)"
                elif isinstance(dec.func, ast.Attribute):
                    if isinstance(dec.func.value, ast.Name):
                        dec_str = f"@{dec.func.value.id}.{dec.func.attr}"
            elif isinstance(dec, ast.Attribute):
                if isinstance(dec.value, ast.Name):
                    dec_str = f"@{dec.value.id}.{dec.attr}"

            if dec_str:
                dec_idx = self._add_to_array(dec_str, self.decorators, self.decorators_index)
                decorators.append([dec.lineno, dec_idx])

        return decorators

    def _find_body_start(self, node, docstring_coords: Optional[List[int]]) -> int:
        """–ù–∞–π—Ç–∏ –Ω–∞—á–∞–ª–æ —Ç–µ–ª–∞"""
        if docstring_coords:
            return docstring_coords[1] + 1

        if node.body:
            return node.body[0].lineno

        return node.lineno + 1

    def _get_indentation(self, lines: List[str], line_num: int) -> int:
        """–ü–æ–ª—É—á–∏—Ç—å —É—Ä–æ–≤–µ–Ω—å –æ—Ç—Å—Ç—É–ø–∞"""
        if 0 <= line_num - 1 < len(lines):
            line = lines[line_num - 1]
            return len(line) - len(line.lstrip())
        return 0

    def _extract_comments(self, file_id: int, lines: List[str]):
        """–ò–∑–≤–ª–µ—á—å –≤–∞–∂–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π –ø–æ–∏—Å–∫)"""
        for line_num, line in enumerate(lines, 1):
            for comment_type, pattern in self.comment_patterns.items():
                match = pattern.search(line)
                if match:
                    content = match.group(1).strip()
                    type_idx = self.comment_types[comment_type]
                    content_idx = self._add_to_array(content, self.commenttexts, 
                                                     self.commenttexts_index)

                    # [file_id, line, type_idx, content_idx]
                    self.comments.append([file_id, line_num, type_idx, content_idx])

    def _process_module(self, module_idx: int, tree: ast.Module, file_id: int):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –º–æ–¥—É–ª—å"""
        module_data = self.tech_index["modules"][module_idx]
        location_id = module_data[2]

        # –ü–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∏–∑ files
        file_info = self.files[file_id]
        line_count = file_info[1]  # line_count

        docstring_coords = self._extract_docstring_coords(tree)

        # [module_id, location_id, file_id, line_start, line_end, docstring?]
        module_entry = [module_idx, location_id, file_id, 1, line_count]

        if docstring_coords:
            module_entry.append(docstring_coords)

        self.modules.append(module_entry)

    def _process_class(self, class_idx: int, node: ast.ClassDef, file_id: int, lines: List[str]):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–ª–∞—Å—Å"""
        class_data = self.tech_index["classes"][class_idx]
        location_id = class_data[5]

        decorators = self._extract_decorators_compact(node)
        line_start = decorators[0][0] if decorators else node.lineno
        line_end = node.end_lineno

        docstring_coords = self._extract_docstring_coords(node)
        body_start = self._find_body_start(node, docstring_coords)
        indentation = self._get_indentation(lines, node.lineno)

        # [class_id, location_id, file_id, line_start, line_end, definition_line, 
        #  body_start, indentation, decorators?, docstring?]
        class_entry = [class_idx, location_id, file_id, line_start, line_end, 
                      node.lineno, body_start, indentation]

        if decorators:
            class_entry.append(decorators)

        if docstring_coords:
            if len(class_entry) == 8:
                class_entry.append([])
            class_entry.append(docstring_coords)

        self.classes.append(class_entry)

    def _process_function(self, func_idx: int, node, file_id: int, lines: List[str]):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é"""
        func_data = self.tech_index["functions"][func_idx]
        location_id = func_data[7]

        decorators = self._extract_decorators_compact(node)
        line_start = decorators[0][0] if decorators else node.lineno
        line_end = node.end_lineno

        docstring_coords = self._extract_docstring_coords(node)
        body_start = self._find_body_start(node, docstring_coords)
        indentation = self._get_indentation(lines, node.lineno)

        # [function_id, location_id, file_id, line_start, line_end, signature_line,
        #  body_start, indentation, decorators?, docstring?]
        func_entry = [func_idx, location_id, file_id, line_start, line_end,
                     node.lineno, body_start, indentation]

        if decorators:
            func_entry.append(decorators)

        if docstring_coords:
            if len(func_entry) == 8:
                func_entry.append([])
            func_entry.append(docstring_coords)

        self.functions.append(func_entry)

    def _process_imports(self, tree: ast.Module, file_id: int):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–º–ø–æ—Ä—Ç—ã"""
        import_idx = len(self.imports)

        for node in tree.body:
            if isinstance(node, ast.Import):
                for alias in node.names:
                    # [import_id, file_id, line, type] type: 0=import
                    self.imports.append([import_idx, file_id, node.lineno, 0])
                    import_idx += 1

            elif isinstance(node, ast.ImportFrom):
                for alias in node.names:
                    # [import_id, file_id, line, type] type: 1=from_import
                    self.imports.append([import_idx, file_id, node.lineno, 1])
                    import_idx += 1

    def _process_file(self, file_id: int):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª"""
        file_path_rel = self.tech_index["files"][file_id]
        file_path = self.project_root / file_path_rel

        if not file_path.exists():
            return

        tree, lines = self._parse_file(file_path)
        if not tree:
            return

        # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π –ø–æ–∏—Å–∫)
        self._extract_comments(file_id, lines)

        # –ò–º–ø–æ—Ä—Ç—ã
        self._process_imports(tree, file_id)

        # –ú–æ–¥—É–ª–∏
        for module_idx, module_data in enumerate(self.tech_index["modules"]):
            if module_data[1] == file_id:
                self._process_module(module_idx, tree, file_id)

        # –ö–ª–∞—Å—Å—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏
        self._process_ast_node(tree, file_id, lines)

    def _process_ast_node(self, node, file_id: int, lines: List[str]):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å AST"""
        for item in node.body if hasattr(node, 'body') else []:
            if isinstance(item, ast.ClassDef):
                for class_idx, class_data in enumerate(self.tech_index["classes"]):
                    class_name_idx = class_data[1]
                    class_name = self.tech_index["names"][class_name_idx]

                    if class_name == item.name:
                        if not any(c[0] == class_idx for c in self.classes):
                            self._process_class(class_idx, item, file_id, lines)

                            # –ú–µ—Ç–æ–¥—ã
                            for method in item.body:
                                if isinstance(method, (ast.FunctionDef, ast.AsyncFunctionDef)):
                                    for func_idx, func_data in enumerate(self.tech_index["functions"]):
                                        func_class_idx = func_data[1]
                                        func_name_idx = func_data[2]
                                        func_name = self.tech_index["names"][func_name_idx]

                                        if func_class_idx == class_idx and func_name == method.name:
                                            if not any(f[0] == func_idx for f in self.functions):
                                                self._process_function(func_idx, method, file_id, lines)
                        break

            elif isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):
                for func_idx, func_data in enumerate(self.tech_index["functions"]):
                    func_class_idx = func_data[1]
                    func_name_idx = func_data[2]
                    func_name = self.tech_index["names"][func_name_idx]

                    if func_class_idx == -1 and func_name == item.name:
                        if not any(f[0] == func_idx for f in self.functions):
                            self._process_function(func_idx, item, file_id, lines)
                        break

    def build(self):
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å"""
        print(f"üîç –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ TECH-LOCATION v2.0 –¥–ª—è: {self.project_root}")

        files = self.tech_index["files"]
        total_files = len(files)

        # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª—ã
        for file_id in range(total_files):
            print(f"  [{file_id + 1}/{total_files}] {files[file_id]}")
            self._process_file_info(file_id)
            self._process_file(file_id)

        # –û–±–Ω–æ–≤–∏—Ç—å —Å—á–µ—Ç—á–∏–∫–∏
        self.meta["totalobjects"]["modules"] = len(self.modules)
        self.meta["totalobjects"]["classes"] = len(self.classes)
        self.meta["totalobjects"]["functions"] = len(self.functions)
        self.meta["totalobjects"]["imports"] = len(self.imports)
        self.meta["totalobjects"]["comments"] = len(self.comments)

        print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ:")
        print(f"   –ú–æ–¥—É–ª–µ–π: {len(self.modules)}")
        print(f"   –ö–ª–∞—Å—Å–æ–≤: {len(self.classes)}")
        print(f"   –§—É–Ω–∫—Ü–∏–π: {len(self.functions)}")
        print(f"   –ò–º–ø–æ—Ä—Ç–æ–≤: {len(self.imports)}")
        print(f"   –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {len(self.comments)}")

    def save(self, output_path: Path):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω–¥–µ–∫—Å"""
        output_path.mkdir(parents=True, exist_ok=True)

        project_name = self.project_root.name
        ext = ".json.gz" if self.output_format == "json.gz" else ".json"
        output_file = output_path / f"tech-location-{project_name}-v2{ext}"

        # –°–æ–±—Ä–∞—Ç—å –∏–Ω–¥–µ–∫—Å
        location_index = {
            "meta": self.meta,
            "paths": self.paths,
            "modifieds": self.modifieds,
            "hashes": self.hashes,
            "decorators": self.decorators,
            "commenttexts": self.commenttexts,
            "files": self.files,
            "modules": self.modules,
            "classes": self.classes,
            "functions": self.functions,
            "imports": self.imports,
            "comments": self.comments
        }

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
        if self.output_format == "json":
            if self.minify:
                # –ú–∏–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON (–±–µ–∑ –æ—Ç—Å—Ç—É–ø–æ–≤)
                json_data = json.dumps(location_index, separators=(',', ':'), ensure_ascii=False)
            else:
                # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON (—Å –æ—Ç—Å—Ç—É–ø–∞–º–∏)
                json_data = json.dumps(location_index, indent=2, ensure_ascii=False)
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(json_data)
        else:
            # GZIP –≤—Å–µ–≥–¥–∞ –º–∏–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
            json_data = json.dumps(location_index, separators=(',', ':'), ensure_ascii=False)
            with gzip.open(output_file, 'wb', compresslevel=9) as f:
                f.write(json_data.encode('utf-8'))

        file_size = output_file.stat().st_size

        print(f"\n‚úÖ TECH-LOCATION v2.0 —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
        print(f"üìä –†–∞–∑–º–µ—Ä: {file_size:,} –±–∞–π—Ç ({file_size/1024:.1f} –ö–ë)")


def find_tech_index(index_dir: Path, project_name: str) -> Optional[Path]:
    """–ù–∞–π—Ç–∏ TECH-INDEX"""
    patterns = [
        f"tech-index-py-{project_name}-v3.json",
        f"tech-index-py-{project_name}-v3.json.gz"
    ]

    for pattern in patterns:
        index_file = index_dir / pattern
        if index_file.exists():
            return index_file

    for file in index_dir.glob("tech-index-py-*-v3.json*"):
        return file

    return None


def main():
    parser = argparse.ArgumentParser(description='TECH-LOCATION Builder v2.0 (Compact)')

    parser.add_argument('project_path', help='–ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É')
    parser.add_argument('tech_index_dir', help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å TECH-INDEX')
    parser.add_argument('output_dir', help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è TECH-LOCATION')
    parser.add_argument('--format', default='json', choices=['json', 'json.gz'],
                       help='–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞')
    parser.add_argument('--minify', action='store_true',
                       help='–ú–∏–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON (–±–µ–∑ –æ—Ç—Å—Ç—É–ø–æ–≤)')

    args = parser.parse_args()

    project_path = Path(args.project_path).resolve()
    tech_index_dir = Path(args.tech_index_dir).resolve()
    output_dir = Path(args.output_dir).resolve()

    if not project_path.exists():
        print(f"‚ùå –ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {project_path}")
        sys.exit(1)

    if not tech_index_dir.exists():
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {tech_index_dir}")
        sys.exit(1)

    project_name = project_path.name
    tech_index_file = find_tech_index(tech_index_dir, project_name)

    if not tech_index_file:
        print(f"‚ùå TECH-INDEX –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {tech_index_dir}")
        sys.exit(1)

    print("=" * 70)
    print("TECH-LOCATION Builder v2.0 (Compact)")
    print("=" * 70)
    print(f"üìÅ –ü—Ä–æ–µ–∫—Ç: {project_path}")
    print(f"üìã TECH-INDEX: {tech_index_file.name}")
    print(f"üíæ –í—ã–≤–æ–¥: {output_dir}")
    print(f"üìù –§–æ—Ä–º–∞—Ç: {args.format}" + (" (minified)" if args.minify else ""))
    print("=" * 70)

    try:
        builder = LocationIndexBuilderV2(
            str(project_path),
            str(tech_index_file),
            output_format=args.format,
            minify=args.minify
        )

        builder.build()
        builder.save(output_dir)

        print("\n‚ú® –ì–æ—Ç–æ–≤–æ!")

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
